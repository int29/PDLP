{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eafd0166-f68a-4c31-8f1a-1f444f9c373b",
   "metadata": {},
   "source": [
    "# Practical Deep-Learning using Pytorch\n",
    "* project start : 2023-03-23\n",
    "* project end : \n",
    "* wirter : Int29\n",
    "* github : https://github.com/int29/PDLP\n",
    "* project description : 처음부터 다시 딥러닝 공부를 하면서 공부한 내용을 정리함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348c4f06-7750-4541-a393-b192afdd0340",
   "metadata": {},
   "source": [
    "## Chapter01 : classical artificial neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871d8108",
   "metadata": {},
   "source": [
    "## 01.퍼셉트론(Perceptron) : Artificial neuron의 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392f247d-a7d4-4686-9045-6d50391a742a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (1) 생각보다 간단하게 표현된 뉴런 : MCP 모형\n",
    "퍼셉트론은 1957년 로젠 블릿이 MCP(McCulloch-Pitts)뉴런모형을 기반으로하는 학습알고리즘을 발표하며 탄생하였다. 로젠 블릿이 차용한 MCP뉴런모형이란 1943년 월터 피츠(Walter Pitts)와 워렌 맥컬러히(Warren McCulloch)가 실제 뉴런이 수상돌기를 통해 전달된 신호가 임계치 이상으로 전달될 때 전기신호를 출력하는것을 수학적으로 단순화시켜 모델링한 것이다. MPC모형에서 뉴런은 0과1의 이진(binary)값을 입력받고 출력하며 각 입력 신호에 가중치(weight)를 곱한값의 합이 임계값(threshold)을 넘으면 1, 그렇지 않으면 0을 반환한다.\n",
    "<br><br><br>\n",
    "\n",
    "<br><br><br>\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://github.com/int29/PDLP/blob/main/ch01_classical_neural_network/01_01.png?raw=true\" width=\"500\">\n",
    "    <span>[그림01-01]</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed64b52b",
   "metadata": {},
   "source": [
    "\n",
    "### (2) MCP뉴런에서 퍼셉트론으로\n",
    "MCP모형을 기반으로 로젠블릿은 입력값($x$)에 가중치($w$)를 곱한 값에 편향($b$,bias)을 더하는 선형모형에 활성화 함수를 적용하여 출력값을 계산하는 임계치모형과 선형모형의 파라미터인 가중치($w$)와 편향($b$)을 학습하는 학습알고리즘인 퍼셉트론을 발표하였다.\n",
    "\n",
    "<br><br><br>\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://github.com/int29/PDLP/blob/main/ch01_classical_neural_network/01_02.png?raw=true\" width=\"700\">\n",
    "    <span>[그림01-02]</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2220488b",
   "metadata": {},
   "source": [
    "### (2-1) 퍼셉트론의 가중치와 편향 \n",
    "퍼셉트론은 복수의 입력에 개별 가중치를 곱하고 편향을 더한다. 때문에 가중치($w$)에 따라 특정 입력이 활성화에 강하게 영향을 미칠수도 반대로 적게 미치게될 수도 있다. 또한 편향($b$)을 더해주기 때문에 이 편향값에 따라 약한 신호에서도 활성화가 잘될지(민감) 아니면 강한신호에도 활성화가 잘 되지 않을지(둔감)하게 될 수도 있다. \n",
    "\n",
    "* 가중치($w$) : 여러 입력 신호 중 출력신호에 영향을 주는 중요도를 결정한다.\n",
    "* 편향($b$) : 활성함수가 입력신호에 대해 얼마나 민감하게 반응할지 결정한다.\n",
    "\n",
    "입력신호는 $x=[1,1,1]$와 같고 각 입력신호에 전달되는 가중치가 $w=[0.1,0.2,10]$이라면 활성함수에 전달되는 값은 \n",
    "$1\\times0.1 + 1\\times0.2 + 1\\times10$이 될것이다. 따라서 3번째 신호의 가중치가 10이기 때문에 활성화여부에 가장 많은 영향을 주는것을 직관적으로 알 수 있다.\n",
    "\n",
    "이 때 임계치가 $\\theta=15$라면 위 입력신호의 가중합은 10.3이기 때문에 활성화 되지 않을것이다. 하지만 편향 $b=5$ 라면 퍼셉트론의 식에 따라 입력신호의 가중합에 편향5가 더해져 15.5가 되어 임계치 15를 넘기 때문에 이번에는 활성화된 값인 1을 반환할 것이다. 만약 $b=15$라면 가중치가 어떠하든 입력신호가 어떠하든 임계치보다 무조건 높기 때문에 무조건 1을 반환하게 될것이다. 즉 편향($bias$)가 입력신호에 얼마나 민감하게 반응할지를 결정하는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8976794e",
   "metadata": {},
   "source": [
    "### (2-2) 활성화 함수(activation function)\n",
    "활성화 함수(activation function)는 인공신경망에서 입력 신호의 총합을 출력값으로 변환하는 함수이다. 즉 퍼셉트론이 입력값을 계산한 값을 binary값으로 변경해주는 것이다. 가장 기본적인 활성함수는 계단함수(Step Function)이고 이 계단함수를 통해서 작동에 대해 살펴보자\n",
    "\n",
    "계단함수는 매우 간단하다. 계단함수로 입력되는 값이 임계값($\\theta$)보다 높으면 1을 출력하고, 낮으면 0을 출력한다. 위 예시에서 임계값이 15이기 때문에 아래와 같이 표현할 수 있다.\n",
    "<br><br>\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://github.com/int29/PDLP/blob/main/ch01_classical_neural_network/01_05.png?raw=true\" width=\"400\">\n",
    "    <span>[그림01-03]</span>\n",
    "</div>\n",
    "\n",
    "실제 사용가능한 활성화함수는 아래와 같이 매우 다양하며 포함되지 않은 함수들도 존재한다. 만약 맞는 함수가 없다면 직접 만들 수도 있다.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://github.com/int29/PDLP/blob/main/ch01_classical_neural_network/01_04.png?raw=true\" width=\"400\">\n",
    "    <span>[그림01-04]</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb72b8d1",
   "metadata": {},
   "source": [
    "## 02. 퍼셉트론(Perceptron) 구현\n",
    "### (1) pytorch를 AND/OR/NAND 구현\n",
    "pytorch를 통해서 계단함수를 활성함수로 사용하는 퍼셉트론을 생성해보고 AND / OR / NAND 문제를 해결해보자\n",
    "AND / OR / NAND 문제는 $x_{1}$, $x_{2}$ 두 개의 입력값에 따라 하나의 출력 $y$를 어떻게 내보낼것인가에 대한 문제이다.  신호를 1과 0으로 표현하고, 입력하는 신호를 처리하는 방법에 따라서 출력 $y$에 신호를 1로 내보낼것인지 0으로 내보낼것인지를 결정한다.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://github.com/int29/PDLP/blob/main/ch01_classical_neural_network/01_06.png?raw=true\" width=\"400\">\n",
    "    <span>[그림01-06]</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caff87f5",
   "metadata": {},
   "source": [
    "### (1-1) AND 게이트\n",
    "AND의 경우 두개의 입력 신호값이 모두 1일 경우만 신호를 1로 출력한다. 이 입력과 출력관계를 2차원 좌표평면상으로 표현하면 오른쪽 그림과 같다.\n",
    "우리의 목표는 2차원 좌표평면상에 $(x_{1},x_{2})=\\{(0,0),(0,1),(1,0),(1,1)\\}$ 4개의 점이 존재할 때, $\\{(0,0),(0,1),(1,0),\\}$ 3개의 점은 0으로, 1개의 점\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://github.com/int29/PDLP/blob/main/ch01_classical_neural_network/01_07.png?raw=true\" width=\"400\">\n",
    "    <span>[그림01-07]</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "141ae153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# AND 게이트 문제 데이터셋\n",
    "x_data = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_data = torch.FloatTensor([[0], [0], [0], [1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fd695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\\begin{equation}\n",
    "  f(x)=\\left\\{\n",
    "  \\begin{array}{@{}ll@{}}\n",
    "    0, & \\text{if}\\ & w_{1}x_{1} + w_{2}x_{2} + ... w_{n}x_{n} + b < \\theta \\\\\n",
    "    1, & \\text{if} \\ & w_{1}x_{1} + w_{2}x_{2} + ... w_{n}x_{n} + b >= \\theta \\\\\n",
    "  \\end{array}\\right.\n",
    "\\end{equation} \n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "  f(x) &= \\sum_{i=1}^{N} w_{i}x_{i} +b\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530ee3bf-363c-47ea-9e56-4ff98d40d32b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 인용출처\n",
    "$^{[1]}$ : 파이썬 머신러닝(2016),세바스티안 라슈카,지앤선,PACKT, 17p~18p\n",
    "\n",
    "<원문>\n",
    "\n",
    "워런 맥컬럭과 월터 피츠가 맥컬럭-피츠(MCP) 뉴런이라고 불리는 단순화된 뇌 세포의 개념을 1943년 처음 발표하면서 시작되었다.(A Logical Calculus of the Ideas Immanent in Nervous Activity by W. S. McCulloch and W. Pitts, Bulletin of Mathematical Biophysics, 5(4): 115-133, 1943), 메컬렉과 피츠는 이러한 신경세포를 바이너리 출력을 갖는 간단한 논리 게이트로 설명했다. 복수의 신호가 수상돌기에 도달하면 세포체에 통합된다. 그리고 신호가 누적되어 특정 임계치를 초과하면 출력 신호가 생성되고 축색돌기를 지나간다.\n",
    "\n",
    "**참고문헌**\n",
    "1. 파이썬 머신러닝(2016),세바스티안 라슈카,지앤선,PACKT\n",
    "2. 밑바닥부터 시작하는 딥러닝(2021), 사이토 코기, 한빛미디어\n",
    "3. Machine Learning with R Second Edition(2015), Brett Lantz, Packt\n",
    "\n",
    "#### 이미지 및 자료 출처\n",
    "[그림01-01] : 비상학습백과 중학교 과학 ② 뉴런(https://terms.naver.com/entry.naver?docId=3379489&cid=47339&categoryId=47339)<br>\n",
    "[그림01-05] : Machine Learning with R Second Edition(2015), Brett Lantz, Packt<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fede14ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
